---
title: "Tarea 2 - Estad铆stica Actuarial II"
author: 
  - Estudiantes
  - Luis Fernando Amey Apuy - C20470
  - Javier Antonio Hern谩ndez Navarro - C13674
  - Sof铆a Bocker Brenes - C11102
date: "`r Sys.Date()`"
output: 
  rmdformats::robobook:
    highlight: tango
---

# Librer铆as

```{r}
# install.packages("pacman")
pacman::p_load(
  ggplot2, 
  lubridate,
  tidyverse,
  plotly
)
```

# Pregunta 1

## Algoritmo de Integraci贸n por Montecarlo
Usando un Algoritmo de Integraci贸n por Montecarlo estime la siguiente integral: 
$$\int_0^1 \dfrac{e^{-x^2}}{1+x^2} \ dx$$ 
Usando la funci贸n _integrate_ de R, estime que el error de aproximaci贸n sea menor a $10^{-3}$, y mu茅strelo, esta funci贸n integrate utiliza el m茅todo de Simpson

```{r}
# Algoritmo integraci贸n por Montecarlo

# Se establece una semilla
set.seed(2024)
# Se escoge un tama帽o de muestra
n <- 10^4
# Se establece una distribuci贸n uniforme en el intevalo [0,1]
U <- runif(n,0,1)

# Se define la funci贸n f
f <- Vectorize(function(x) (exp(-x^2))/(1+x^2))

# Se genera un vector para cada observaci贸n
Y <- 1*f(U)

# Se estima la integral por medio del m茅todo Montecarlo
integral_montecarlo <- 1*sum(Y)/n

# Se imprime estimaci贸n
print(c('Estimaci贸n de Integraci贸n Montecarlo:', integral_montecarlo))

```

Se estima el error usando la funci贸n integrate de R (la cual utiliza el m茅todo de Simpson):

```{r}
integral_simpson <- integrate(f, 0, 1)
print('Estimaci贸n de Integraci贸n por Simpson:')
integral_simpson

# Se calcula el error
error <- abs(integral_simpson$value - integral_montecarlo)

print(c('Error de aproximaci贸n:', error))

```

Se puede observar que el error de aproximaci贸n es menor a 10^(-3). Se grafica para analizar la convergencia:

```{r}
acumulado<-cumsum(Y)/(1:n)
plot(1:n,acumulado,col="blue",type="l",ylab="Aproximaci贸n",xlab="Iteraciones")
abline(h=integral_simpson$value,col="red",lwd=1)
```

# Pregunta 2

El valor esperado de una funci贸n de p茅rdida en una p贸liza de seguros, donde la p茅rdida $L$, sigue una distribuci贸n exponencial con par谩metro $\lambda = 1$. Queremos estimar el valor esperando de la siguiente funci贸n: 
$$E[L] = \int_0^\infty Lf_L(L) \ dL$$
Donde $f_L(L)$ es la funci贸n de densidad de la distribuci贸n de la p茅rdida $L$

## a) Programar $f_L(L)$
Programe la funci贸n de p茅rdida $f_L(L)$ seg煤n el enunciado

## b) Muestreo por importancia
Para muestrear valores extremos de nuestra muestra, podemos usar una distribuci贸n auxiliar
$$g(L) \sim N(3,4)$$
Implemente un muestreo por importancia con esta funci贸n auxiliar, para $n = 10^4$ e indique el valor esperado de la p茅rdida de los valores extremos, usando como semilla _set.seed(54321)_

```{r}
# Datos dados en el enunciado
set.seed(54321)

n <- 10^4

# Generar la muestra aleatoria de los valores seg煤n la densidad auxiliar
A <- rnorm(n, mean = 3, sd = 2)
A <- A[A>0]

n <- length(A)

# Funci贸n de p茅rdida f_L(L) seg煤n el enunciado
f_L <- Vectorize(function(L) ifelse(L >= 0, exp(-L), 0))

# Funci贸n de densidad auxiliar g_L(L) de la normal N(3, 2^2)
g_L <- Vectorize(function(L) dnorm(L, mean = 3, sd = 2))

# Funci贸n de importancia 
h <- Vectorize(function(L) (L * f_L(L)) / g_L(L))

# Aplicar la funci贸n de importancia a las muestras generadas
Y2 <- h(A)

# Obtener resultado 
valor_esperado <- mean(Y2)

# Mostrar el resultado
print(c("Valor esperado de la p茅rdida de los valores extremos:", valor_esperado))
```


# Pregunta 3
La siguiente muestra indica el tiempo en d铆as entre cada accidente laboral de una empresa:
$$2.72, 1.93, 1.76, 0.49, 6.12, 0.43, 4.01, 1.71, 2.01, 5.96$$
Se sabe que los tiempos entre accidentes poseen una distribuci贸n exponencial de par谩metro $\lambda$. Usaremos como funci贸n a priori de $\lambda$ una distribuci贸n gamma de par谩metros (2,1)

## a) Valor estimado de 
Indique el valor estimado de $\lambda$, utilizando el algoritmo de Aceptaci贸n y Rechazo.

```{r}
mas_acc_lab <- c(2.72, 1.93, 1.76, 0.49, 6.12, 0.43, 4.01, 1.71, 2.01, 5.96)
s_acc_lab <- sum(mas_acc_lab)
n_acc_lab <- length(mas_acc_lab)
m_acc_lab <- s_acc_lab/n_acc_lab
```

Puesto as铆, nuestra funci贸n de verosimilitud de $\lambda$ es una $\Gamma(11, 27.14)$
Ahora comprobamos que podemos usar la funci贸n dgamma para nuestra verosimilitud
```{r}
vero <- function(x) (exp(-27.14*x)*x^10)/6.165801e-10 # constante de integracion
dgamma1 <- function(x) dgamma(x, 11, 27.14)
xx <- seq(0,1,length.out = 1000)
df <- data.frame(
  x = xx,
  vero = vero(xx),
  gamma = dgamma1(xx)
)
ggplot(df, aes(x = x)) +
  geom_line(aes(y = vero, color = 'red'), alpha = 1, linewidth = 3) +
  geom_point(aes(y = gamma), alpha = 0.5)
```
Y nuestra funci贸n posteriori de $\lambda$ es una $\Gamma(12, 28.14)$
Al maximizar nuestra funci贸n $\frac{f(x)}{g(x)}$, tomando a $g \sim \Gamma(2,1)$
```{r}
maxc <- 10/27.14
c <- dgamma(maxc, 12, 27.14)
```

```{r}
U <- runif(10^4)
x <- rgamma(10^4,2,1)
ngen <- length(x)
dgamma1 <- Vectorize(function(x) dgamma(x, 11, 27.14))
DIB <- dgamma1(x)
for(i in 1:10^4){
  while((U[i]*c) >= (DIB[i])){ 
    U[i] <- runif(1)
    x[i] <- rgamma(1, 2, 1)
    DIB[i] <- dgamma1(x[i])
    ngen <- ngen+1
  }
}
lambda <- mean(x)
print(paste("El valor estimado de lambda es", round(lambda, digits = 4)))
```

## b) Distribuci贸n de 
Construya el histograma para la distribuci贸n de $\lambda$

```{r}
fig <- ggplot(data.frame(x = x), aes(x = x)) +
  geom_histogram(aes(y = after_stat(density), color = "Histograma"), bins = 40, fill = "lightblue", alpha = 0.5) +
  stat_function(fun = function(x) dgamma(x, 12, 28.14), aes(color = "Densidad Te贸rica"), size = 1.5) +
  labs(title = "Histograma de Lambda", x = "x", y = "Density", color = "Leyenda", fill = " ") +
  scale_color_manual(values = c("cyan", "black")) +
  theme(legend.position = 'bottom') +
  theme_minimal() 
fig %>% ggplotly()
```

## c) Generaciones
Indique el n煤mero de generaciones, n煤mero medio de generaciones y proporci贸n de rechazos de la estimaci贸n realizada

```{r}
{cat("N煤mero de generaciones = ", ngen)
cat("\nN煤mero medio de aceptados = ", ngen/10^4)
cat("\nProporci贸n de rechazos = ", 1-10^4/ngen, "\n")}
```

## d) Intervalo de credibilidad
Determine un intervalo de credibilidad al 99% para el par谩metro $\lambda$ estimado

```{r}
quantile(x, c(0.005, 0.995))
```

## e) Hip贸tesis
Aceptar铆a o rechazar铆a la hip贸tesis que $\lambda = 0.5$, basados en el intervalo de credibilidad anterior. 

Podemos aceptar esta hip贸tesis ya que se encuentra dentro del intervalo de credibilidad anterior y bastante cerca de nuestro valor lambda. Solo la rechazamos cuando tenemos un intervalo de credibilidad aproximado de 50%
```{r}
quantile(x, c(0.25, 0.75))
```


# Pregunta 4
Sea $f(x) = \exp\left(\frac{\sin(10x)}{10\cos(x)}\right)$, para $x \in [0,10]$

## a) Algoritmo de recalentamiento simulado
Utilizando el algoritmo de recalentamiento simulado estime el m铆nimo global en [0,10], con valor inicial en 5

```{r}
resim <- function(f, alpha=0.5, s0=0, niter,mini=-Inf,maxi=Inf) {
  s_n <- s0
  estados<-rep(0,niter)
  iter_count <- 0
  for (k in 1:niter) {
    estados[k]<-s_n
    T <- (1 - alpha)^k
    s_new <- rnorm(1, s_n, 1)
    if(s_new<mini){s_new=mini}
    if(s_new>maxi){s_new=maxi}
    dif <- f(s_new) - f(s_n)
    if (dif < 0) {
      s_n = s_new
    } else {
      random <- runif(1,0,1)
      if (random < exp(-dif/T)) {
      s_n <- s_new
      }
    }
    iter_count <- iter_count + 1
  }
  return(list(r=s_n,e=estados))
}
```


```{r}
f <- function(x) exp(sin(10*x)/(10*cos(x)))
Resultado <-resim(f,0.1,5,10000,0,10) # 10e3 puesto se quedaba varado en algunas
print(paste("El valor del m铆nimo global en [0,10] es", round(Resultado$r,digits = 4)))
```


## b) Gr谩fico de estados 
Grafique el resultado de los estados donde estuvo la cadena de la estimaci贸n del punto a.

```{r, echo=FALSE}
par(mfrow = c(1, 2))
plot(f, xlim = c(0, 10))
plot(Resultado$e)
par(mfrow = c(1, 1))
```


# Pregunta 5
Dada una muestra de siniestros observados por periodo:
$$4,2,5,6,3,4,7,5,6,4$$
Suponemos que el n煤mero de siniestros en cada periodo sigue una distribuci贸n de Poisson con un par谩metro $\lambda$. Queremos estimar el par谩metro $\lambda$ usando el Algoritmo de *Metropolis-Hastings*, usaremos como funci贸n a priori de $\lambda$ una distribuci贸n gamma de par谩metros (3,2)

## a) Algoritmo de Metropolis-Hastings
Construya un algoritmo de Metropolis-Hastings que muestree el par谩metro $\lambda$, a partir de los datos suministrados con $n = 10^4$

```{r}
# Muestra de siniestros observados
siniestros <- c(4, 2, 5, 6, 3, 4, 7, 5, 6, 4)

# Funci贸n de densidad de la priori Gamma
log_priori <- function(lambda) {
  dgamma(lambda, shape = 3, scale = 2, log = TRUE)
}

# Funci贸n de densidad de Poisson para los siniestros
log_verosimilitud <- function(datos, lambda) {
  sum(dpois(datos, lambda, log = TRUE))
}

# Funci贸n posterior
log_posterior <- function(lambda, datos) {
  log_verosimilitud(datos, lambda) + log_priori(lambda)
}

# Algoritmo de Metropolis-Hastings
metropolis_hastings <- function(datos, n_iteraciones) {
  
  cadena_lambda <- numeric(n_iteraciones)
  cadena_lambda[1] <- runif(1, min = min(datos), max = max(datos))
  aceptaciones <- 0
  
  for (i in 2:n_iteraciones) {
    lambda_actual <- cadena_lambda[i - 1]
    lambda_propuesto <- rnorm(1, mean = lambda_actual, sd = 1)
    
    if (lambda_propuesto > 0) {
      log_alpha <- log_posterior(lambda_propuesto, datos) - log_posterior(lambda_actual, datos)
      alpha <- min(1, exp(log_alpha))
      
      if (runif(1) < alpha) {
        cadena_lambda[i] <- lambda_propuesto
        aceptaciones <- aceptaciones + 1
      } else {
        cadena_lambda[i] <- lambda_actual
      }
    } else {
      cadena_lambda[i] <- lambda_actual
    }
  }
  
  # Quema los primeros 1000 valores (burn in)
  list(cadena = cadena_lambda[-(1:1000)], tasa_aceptacion = aceptaciones / n_iteraciones)
}

# Ejecuta el algoritmo con n = 10000
resultado <- metropolis_hastings(siniestros, n_iteraciones = 10000)
cadena_lambda <- resultado$cadena
tasa_aceptacion <- resultado$tasa_aceptacion

promedios <- cumsum(cadena_lambda) / (1:length(cadena_lambda))
cat("La estimaci贸n de lambda es:", promedios[length(promedios)])
```


## b) Histograma
Grafique la distribuci贸n (histograma) de la muestra MCMC del algoritmo.

```{r}
hist(cadena_lambda, breaks = 50, freq = FALSE, 
     main = "Histograma de lambda (MCMC)", 
     xlab = expression(lambda), col = "salmon")
```


## c) Traceplot
Gr谩fique el Traceplot de muestra MCMC del algoritmo

```{r}
plot(cadena_lambda, type = "l", 
     main = "Traceplot de la muestra MCMC", 
     ylab = expression(lambda), xlab = "Iteraciones")
```


## d) Autocorrelaci贸n
El gr谩fico de Autocorrelaci贸n de la muestra MCMC del algoritmo.

```{r}
acf(cadena_lambda, main = "Autocorrelaci贸n de la muestra MCMC")
```


## e) Convergencia de la media
El gr谩fico de la convergencia (promedios erg贸dicos) de la media de la muestra MCMC del algoritmo.

```{r}
plot(promedios, type = "l", 
     main = "Convergencia (Promedios erg贸dicos)", 
     ylab = "Promedio acumulado de lambda", xlab = "Iteraciones")
```


## f) Aceptaci贸n
La tasa de aceptaci贸n del algoritmo.

```{r}
cat("Tasa de aceptaci贸n:", tasa_aceptacion)
```

