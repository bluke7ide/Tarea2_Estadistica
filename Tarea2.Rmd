---
title: "Tarea 2 - Estadística Actuarial II"
author: 
  - Estudiantes
  - Luis Fernando Amey Apuy - C20470
  - Javier Antonio Hernández Navarro - C13674
  - Sofía Bocker Brenes - C11102
date: "`r Sys.Date()`"
output: 
  rmdformats::robobook:
    highlight: tango
---

# Librerías

```{r}
# install.packages("pacman")
pacman::p_load(
  ggplot2, 
  lubridate,
  tidyverse,
  plotly
)
```

# Pregunta 1

## Algoritmo de Integración por Montecarlo
Usando un Algoritmo de Integración por Montecarlo estime la siguiente integral: 
$$\int_0^1 \dfrac{e^{-x^2}}{1+x^2} \ dx$$ 
Usando la función _integrate_ de R, estime que el error de aproximación sea menor a $10^{-3}$, y muéstrelo, esta función integrate utiliza el método de Simpson

```{r}
# Algoritmo integración por Montecarlo

# Se establece una semilla
set.seed(2024)
# Se escoge un tamaño de muestra
n <- 10^4
# Se establece una distribución uniforme en el intevalo [0,1]
U <- runif(n,0,1)

# Se define la función f
f <- Vectorize(function(x) (exp(-x^2))/(1+x^2))

# Se genera un vector para cada observación
Y <- 1*f(U)

# Se estima la integral por medio del método Montecarlo
integral_montecarlo <- 1*sum(Y)/n

# Se imprime estimación
print(c('Estimación de Integración Montecarlo:', integral_montecarlo))

```

Se estima el error usando la función integrate de R (la cual utiliza el método de Simpson):

```{r}
integral_simpson <- integrate(f, 0, 1)
print('Estimación de Integración por Simpson:')
integral_simpson

# Se calcula el error
error <- abs(integral_simpson$value - integral_montecarlo)

print(c('Error de aproximación:', error))

```

Se puede observar que el error de aproximación es menor a 10^(-3). Se grafica para analizar la convergencia:

```{r}
acumulado<-cumsum(Y)/(1:n)
plot(1:n,acumulado,col="blue",type="l",ylab="Aproximación",xlab="Iteraciones")
abline(h=integral_simpson$value,col="red",lwd=1)
```

# Pregunta 2

El valor esperado de una función de pérdida en una póliza de seguros, donde la pérdida $L$, sigue una distribución exponencial con parámetro $\lambda = 1$. Queremos estimar el valor esperando de la siguiente función: 
$$E[L] = \int_0^\infty Lf_L(L) \ dL$$
Donde $f_L(L)$ es la función de densidad de la distribución de la pérdida $L$

## a) Programar $f_L(L)$
Programe la función de pérdida $f_L(L)$ según el enunciado

## b) Muestreo por importancia
Para muestrear valores extremos de nuestra muestra, podemos usar una distribución auxiliar
$$g(L) \sim N(3,4)$$
Implemente un muestreo por importancia con esta función auxiliar, para $n = 10^4$ e indique el valor esperado de la pérdida de los valores extremos, usando como semilla _set.seed(54321)_

```{r}
# Datos dados en el enunciado
set.seed(54321)

n <- 10^4

# Generar la muestra aleatoria de los valores según la densidad auxiliar
A <- rnorm(n, mean = 3, sd = 2)
A <- A[A>0]

n <- length(A)

# Función de pérdida f_L(L) según el enunciado
f_L <- Vectorize(function(L) ifelse(L >= 0, exp(-L), 0))

# Función de densidad auxiliar g_L(L) de la normal N(3, 2^2)
g_L <- Vectorize(function(L) dnorm(L, mean = 3, sd = 2))

# Función de importancia 
h <- Vectorize(function(L) (L * f_L(L)) / g_L(L))

# Aplicar la función de importancia a las muestras generadas
Y2 <- h(A)

# Obtener resultado 
valor_esperado <- mean(Y2)

# Mostrar el resultado
print(c("Valor esperado de la pérdida de los valores extremos:", valor_esperado))
```


# Pregunta 3
La siguiente muestra indica el tiempo en días entre cada accidente laboral de una empresa:
$$2.72, 1.93, 1.76, 0.49, 6.12, 0.43, 4.01, 1.71, 2.01, 5.96$$
Se sabe que los tiempos entre accidentes poseen una distribución exponencial de parámetro $\lambda$. Usaremos como función a priori de $\lambda$ una distribución gamma de parámetros (2,1)

## a) Valor estimado de 𝜆
Indique el valor estimado de $\lambda$, utilizando el algoritmo de Aceptación y Rechazo.

```{r}
mas_acc_lab <- c(2.72, 1.93, 1.76, 0.49, 6.12, 0.43, 4.01, 1.71, 2.01, 5.96)
s_acc_lab <- sum(mas_acc_lab)
n_acc_lab <- length(mas_acc_lab)
m_acc_lab <- s_acc_lab/n_acc_lab
```

Puesto así, nuestra función de verosimilitud de $\lambda$ es una $\Gamma(11, 27.14)$
Ahora comprobamos que podemos usar la función dgamma para nuestra verosimilitud
```{r}
vero <- function(x) (exp(-27.14*x)*x^10)/6.165801e-10 # constante de integracion
dgamma1 <- function(x) dgamma(x, 11, 27.14)
xx <- seq(0,1,length.out = 1000)
df <- data.frame(
  x = xx,
  vero = vero(xx),
  gamma = dgamma1(xx)
)
ggplot(df, aes(x = x)) +
  geom_line(aes(y = vero, color = 'red'), alpha = 1, linewidth = 3) +
  geom_point(aes(y = gamma), alpha = 0.5)
```
Y nuestra función posteriori de $\lambda$ es una $\Gamma(12, 28.14)$
Al maximizar nuestra función $\frac{f(x)}{g(x)}$, tomando a $g \sim \Gamma(2,1)$
```{r}
maxc <- 10/27.14
c <- dgamma(maxc, 12, 27.14)
```

```{r}
U <- runif(10^4)
x <- rgamma(10^4,2,1)
ngen <- length(x)
dgamma1 <- Vectorize(function(x) dgamma(x, 11, 27.14))
DIB <- dgamma1(x)
for(i in 1:10^4){
  while((U[i]*c) >= (DIB[i])){ 
    U[i] <- runif(1)
    x[i] <- rgamma(1, 2, 1)
    DIB[i] <- dgamma1(x[i])
    ngen <- ngen+1
  }
}
lambda <- mean(x)
print(paste("El valor estimado de lambda es", round(lambda, digits = 4)))
```

## b) Distribución de 𝜆
Construya el histograma para la distribución de $\lambda$

```{r}
fig <- ggplot(data.frame(x = x), aes(x = x)) +
  geom_histogram(aes(y = after_stat(density), color = "Histograma"), bins = 40, fill = "lightblue", alpha = 0.5) +
  stat_function(fun = function(x) dgamma(x, 12, 28.14), aes(color = "Densidad Teórica"), size = 1.5) +
  labs(title = "Histograma de Lambda", x = "x", y = "Density", color = "Leyenda", fill = " ") +
  scale_color_manual(values = c("cyan", "black")) +
  theme(legend.position = 'bottom') +
  theme_minimal() 
fig %>% ggplotly()
```

## c) Generaciones
Indique el número de generaciones, número medio de generaciones y proporción de rechazos de la estimación realizada

```{r}
{cat("Número de generaciones = ", ngen)
cat("\nNúmero medio de aceptados = ", ngen/10^4)
cat("\nProporción de rechazos = ", 1-10^4/ngen, "\n")}
```

## d) Intervalo de credibilidad
Determine un intervalo de credibilidad al 99% para el parámetro $\lambda$ estimado

```{r}
quantile(x, c(0.005, 0.995))
```

## e) Hipótesis
Aceptaría o rechazaría la hipótesis que $\lambda = 0.5$, basados en el intervalo de credibilidad anterior. 

Podemos aceptar esta hipótesis ya que se encuentra dentro del intervalo de credibilidad anterior y bastante cerca de nuestro valor lambda. Solo la rechazamos cuando tenemos un intervalo de credibilidad aproximado de 50%
```{r}
quantile(x, c(0.25, 0.75))
```


# Pregunta 4
Sea $f(x) = \exp\left(\frac{\sin(10x)}{10\cos(x)}\right)$, para $x \in [0,10]$

## a) Algoritmo de recalentamiento simulado
Utilizando el algoritmo de recalentamiento simulado estime el mínimo global en [0,10], con valor inicial en 5

```{r}
resim <- function(f, alpha=0.5, s0=0, niter,mini=-Inf,maxi=Inf) {
  s_n <- s0
  estados<-rep(0,niter)
  iter_count <- 0
  for (k in 1:niter) {
    estados[k]<-s_n
    T <- (1 - alpha)^k
    s_new <- rnorm(1, s_n, 1)
    if(s_new<mini){s_new=mini}
    if(s_new>maxi){s_new=maxi}
    dif <- f(s_new) - f(s_n)
    if (dif < 0) {
      s_n = s_new
    } else {
      random <- runif(1,0,1)
      if (random < exp(-dif/T)) {
      s_n <- s_new
      }
    }
    iter_count <- iter_count + 1
  }
  return(list(r=s_n,e=estados))
}
```


```{r}
f <- function(x) exp(sin(10*x)/(10*cos(x)))
Resultado <-resim(f,0.1,5,10000,0,10) # 10e3 puesto se quedaba varado en algunas
print(paste("El valor del mínimo global en [0,10] es", round(Resultado$r,digits = 4)))
```


## b) Gráfico de estados 
Grafique el resultado de los estados donde estuvo la cadena de la estimación del punto a.

```{r, echo=FALSE}
par(mfrow = c(1, 2))
plot(f, xlim = c(0, 10))
plot(Resultado$e)
par(mfrow = c(1, 1))
```


# Pregunta 5
Dada una muestra de siniestros observados por periodo:
$$4,2,5,6,3,4,7,5,6,4$$
Suponemos que el número de siniestros en cada periodo sigue una distribución de Poisson con un parámetro $\lambda$. Queremos estimar el parámetro $\lambda$ usando el Algoritmo de *Metropolis-Hastings*, usaremos como función a priori de $\lambda$ una distribución gamma de parámetros (3,2)

## a) Algoritmo de Metropolis-Hastings
Construya un algoritmo de Metropolis-Hastings que muestree el parámetro $\lambda$, a partir de los datos suministrados con $n = 10^4$

```{r}
# Muestra de siniestros observados
siniestros <- c(4, 2, 5, 6, 3, 4, 7, 5, 6, 4)

# Función de densidad de la priori Gamma
log_priori <- function(lambda) {
  dgamma(lambda, shape = 3, scale = 2, log = TRUE)
}

# Función de densidad de Poisson para los siniestros
log_verosimilitud <- function(datos, lambda) {
  sum(dpois(datos, lambda, log = TRUE))
}

# Función posterior
log_posterior <- function(lambda, datos) {
  log_verosimilitud(datos, lambda) + log_priori(lambda)
}

# Algoritmo de Metropolis-Hastings
metropolis_hastings <- function(datos, n_iteraciones) {
  
  cadena_lambda <- numeric(n_iteraciones)
  cadena_lambda[1] <- runif(1, min = min(datos), max = max(datos))
  aceptaciones <- 0
  
  for (i in 2:n_iteraciones) {
    lambda_actual <- cadena_lambda[i - 1]
    lambda_propuesto <- rnorm(1, mean = lambda_actual, sd = 1)
    
    if (lambda_propuesto > 0) {
      log_alpha <- log_posterior(lambda_propuesto, datos) - log_posterior(lambda_actual, datos)
      alpha <- min(1, exp(log_alpha))
      
      if (runif(1) < alpha) {
        cadena_lambda[i] <- lambda_propuesto
        aceptaciones <- aceptaciones + 1
      } else {
        cadena_lambda[i] <- lambda_actual
      }
    } else {
      cadena_lambda[i] <- lambda_actual
    }
  }
  
  # Quema los primeros 1000 valores (burn in)
  list(cadena = cadena_lambda[-(1:1000)], tasa_aceptacion = aceptaciones / n_iteraciones)
}

# Ejecuta el algoritmo con n = 10000
resultado <- metropolis_hastings(siniestros, n_iteraciones = 10000)
cadena_lambda <- resultado$cadena
tasa_aceptacion <- resultado$tasa_aceptacion

promedios <- cumsum(cadena_lambda) / (1:length(cadena_lambda))
cat("La estimación de lambda es:", promedios[length(promedios)])
```


## b) Histograma
Grafique la distribución (histograma) de la muestra MCMC del algoritmo.

```{r}
hist(cadena_lambda, breaks = 50, freq = FALSE, 
     main = "Histograma de lambda (MCMC)", 
     xlab = expression(lambda), col = "salmon")
```


## c) Traceplot
Gráfique el Traceplot de muestra MCMC del algoritmo

```{r}
plot(cadena_lambda, type = "l", 
     main = "Traceplot de la muestra MCMC", 
     ylab = expression(lambda), xlab = "Iteraciones")
```


## d) Autocorrelación
El gráfico de Autocorrelación de la muestra MCMC del algoritmo.

```{r}
acf(cadena_lambda, main = "Autocorrelación de la muestra MCMC")
```


## e) Convergencia de la media
El gráfico de la convergencia (promedios ergódicos) de la media de la muestra MCMC del algoritmo.

```{r}
plot(promedios, type = "l", 
     main = "Convergencia (Promedios ergódicos)", 
     ylab = "Promedio acumulado de lambda", xlab = "Iteraciones")
```


## f) Aceptación
La tasa de aceptación del algoritmo.

```{r}
cat("Tasa de aceptación:", tasa_aceptacion)
```

